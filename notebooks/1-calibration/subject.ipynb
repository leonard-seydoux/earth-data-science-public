{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# River load sensor calibration\n",
    "\n",
    "![](./images/station-hydrologique-digue.jpeg) \n",
    "Picture of an hydrological station located near La Digue on the Capesterre river © ObsEra.\n",
    "\n",
    "The original version of this notebook was made by Antoine Lucas on top of the study made by Amande Roque-Bernard with the help of Gregory Sainton. In order to know more about the scientific context, please refer to Roque-Bernard et al. ([2023](https://doi.org/10.5194/esurf-11-363-2023)) _Phenomenological model of suspended sediment transport in a small catchment_, Earth Surface Dynamics, 11, 363–381. The dataset comes from [ObsEra](https://www.ozcar-ri.org/fr/observatoire-obsera/) (OBServatoire de l’Eau et de l’éRosion aux Antilles), an observatory located in Guadeloupe that gives us information on the erosion of this volcanic island in a few watersheds. With this notebook, you will learn how to prepare and clean a dataset.\n",
    "\n",
    "The current notebook was edited in 2023 by Léonard Seydoux (seydoux@ipgp.fr) for the course _Earth Data Science_ at the [Institut de Physique du Globe de Paris](https://www.ipgp.fr/fr) (IPGP). If you have found a bug or have a suggestion, please feel free to contact me.\n",
    "\n",
    "<img src=\"images/logo-obsera.png\" style=\"margin:20px; height:100px;\"/> <img src=\"images/logo-ipgp-upc.png\" height=100 style=\"margin:20px; height:100px;\"/>\n",
    "\n",
    "## Instructions\n",
    "\n",
    "This notebook contains a series of questions to which you should answer. Some example cells are given in the notebook to help you. You should not modify these cells. You can add as many cells as you want to answer the questions. You can also add markdown cells to explain your approach. \n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running the notebook, you should make sure that the necessary packages are installed. You can do this by running the following cell. Be sure you are using a correct environment (check the top right corner of the notebook for the name of the environment). Note that there is a blank line between the first import and the other ones. This is because we follow the [PEP8](https://www.python.org/dev/peps/pep-0008/) convention between standard library imports and third party imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Estimating the suspended load within a river is a key issue in geomorphology. The suspended load is often estimated by sampling the water column and measuring the concentration $C_S$ of suspended particles. Although this method is accurate, it is not suitable for long-term monitoring, since it is time-consuming and expensive. A cheaper and faster method is to use turbidity probes. \n",
    "\n",
    "Turbidity probes allow to measure the turbidity $T$ of the water column, which is related to the concentration of suspended particles. However, the relationship between turbidity and suspended load is not straightforward. It depends on the size and the shape of the particles. The goal of this notebook is to calibrate a turbidity probe placed in a river against independent measurements of suspended load. In other terms, we want to find a relationship between the turbidity and the suspended load. And for this, we will use a machine-learning approach.\n",
    "\n",
    "> __Question 1.__ What kind of machine learning problem is this? What is the input $x$, the output $y$? What are the features, the labels, what are the dimensions of the features and the labels spaces? \n",
    "\n",
    "The dataset comes from the _OBServatoire de l’Eau et de l’éRosion aux Antilles_ ([ObsERA](https://www.ozcar-ri.org/fr/observatoire-obsera/)), an observatory located in Guadeloupe that gives us information on the erosion of this volcanic island in a few watersheds. With this notebook, you will learn how to prepare and clean a dataset. It is likely the most important part of the job. Then, you will play with your first models with the `scikit-learn` library. \n",
    "\n",
    "This notebook is mostly dedicated to the dataset preparation and cleaning. This is likely the most important part of the job. Then, you will play with your first models with the `scikit-learn` library. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Suspended load measurements\n",
    "\n",
    "The data for the calibration are stored under the [`./data`](./data) directory. The data are separated in two subsets, one with chemical information which contains the independent measurements of suspended load, and another one with hydrological information which contains the turbidity and water level measurements. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load the chemical data\n",
    "\n",
    "The chemical data comes in a single CSV file located under the [`./data/chemistry`](./data/chemistry) repository. We here load it in a Pandas dataframe with the `pd.read_csv()` function. The goal of this first cell is to correctly parse the data, especially by converting the date and time information into `pd.Timestamp` objects and by selecting the column of interest. Note that the last statement of a Jupyter cell is automatically printed in a better format. \n",
    "\n",
    "> __Question 2.__ What is the `delimiter` keyword argument made for, and why did we set it to a semicolon `;` to load the data? How many rows do we have in this first dataset? And columns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it into a pandas dataframe\n",
    "data_chemical_original = pd.read_csv(\n",
    "    \"./data/chemistry/CE_DIG_OBSERA_RIVERS_2019-09-26.csv\",\n",
    "    delimiter=\";\",\n",
    ")\n",
    "\n",
    "# Print the first 5 rows\n",
    "data_chemical_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Turn the index into a datetime index\n",
    "\n",
    "Note that pandas DataFrames have a special column called the index. You can see above that this column does not have any name and is used to uniquely identify each row of the DataFrame. By default, the index is a sequence of integers from $0$ to $N-1$, where $N$ is the number of rows in the DataFrame. You can also use the date and time information as the index of the DataFrame. This is useful when you want to select a subset of the data based on date and time information. The following cell shows how to do this. Check the new index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy for safety\n",
    "data_chemical_copy = data_chemical_original.copy()\n",
    "\n",
    "# Merge the date and time columns together\n",
    "date_and_time = data_chemical_copy[\"Date\"] + \" \" + data_chemical_copy[\"Hour\"]\n",
    "\n",
    "# Convert the merge into a datetime column\n",
    "data_chemical_copy[\"datetime\"] = pd.to_datetime(date_and_time, format=\"mixed\")\n",
    "\n",
    "# Set the datetime column as the index\n",
    "# The inplace=True keyword argument allows to replace the existing dataframe\n",
    "data_chemical_copy.set_index(\"datetime\", inplace=True)\n",
    "data_chemical_copy.sort_index(inplace=True)\n",
    "\n",
    "# Drop the old date and time columns from the oringal dataframe\n",
    "data_chemical_copy.drop([\"Date\", \"Hour\"], axis=1, inplace=True)\n",
    "\n",
    "# Check head\n",
    "data_chemical_copy.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Select the suspended load column\n",
    "\n",
    "Finally, we extract the data of interest here, a.k.a. the suspended load measurements. Note that since this is only a single column from the `data_chemical_copy` DataFrame, the result is a pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the suspended load\n",
    "suspended_load = data_chemical_copy[\"Suspended Load\"]\n",
    "\n",
    "# Drop the NaN values\n",
    "suspended_load.dropna(inplace=True)\n",
    "\n",
    "# Print the first few rows\n",
    "suspended_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a very handy library to inspect and manipulate data. You can find more information about it in the [documentation](https://pandas.pydata.org/pandas-docs/stable/). For instance, some high-level methods allow you to quickly inspect the data. For instance, the `describe()` method gives you a summary of the data. The `plot()` method allows you to quickly plot the data. You can also use the `head()` and `tail()` methods to inspect the first and last rows of the DataFrame. \n",
    "\n",
    "> __Question 3.__ Can you give a high-level definition of what an object is in Python? This definition should include the notion of _attributes_ and _methods_. According to this definition, what is a DataFrame, and what does the `info()` instruction do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "suspended_load.plot(\n",
    "    style=\".\",\n",
    "    xlabel=\"Date\",\n",
    "    ylabel=\"$C_S$ (mg/L)\",\n",
    "    grid=True,\n",
    "    title=\"Suspended load as a function of time\",\n",
    ")\n",
    "\n",
    "# Describe the data\n",
    "suspended_load.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hydrological data\n",
    "\n",
    "Your turn now! In this part, we will deal with the hydrological data. The ultimate goal of this practical is to use some of the hydrological data to predict the suspended load data. Thus, we need to load the hydrological data into a dataframe. Note that the hydrological data are split into different files. We thus first need to load all the files individually with the `pd.read_csv()` function, and then concatenate them into a single DataFrame with the `pd.concat()` function.\n",
    "\n",
    "First, in order to list all hydrological, you can make use of the `glob.glob()` method.\n",
    "\n",
    "Then, note that the hydrological data contains non-numeric values (missing samples), that have either been replaced in the file by the values -30000.0, NAN or 1e+10 (why would you like something simple?). We will have to deal with these missing values. For that, you can use the `na_values` keyword argument of the `pd.read_csv()` function. Please, check the documentation of this function to see how to use it. For convenience, you can also parse the dates automatically with the `parse_dates` keyword argument. In general, checking the documentation of `pd.read_csv()` is very instructive. You can find it [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).\n",
    "\n",
    "> __Question 4.__ Load the hydrological data into a single DataFrame. Similarly to the chemical data, you should use the date and time information as the index of the DataFrame. What relevant information do you think you should extract from the hydrological data to perform the calibration? Plot one of them as a function of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# Your amazing code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare and inspect the data\n",
    "\n",
    "### 4.1. Synchronize the data\n",
    "\n",
    "You may have realized that the chemical and hydrological data are not synchronized. Actually, the chemical data is sparse in time, whereas the hydrological data is (more or less) continuous with a minimum of 1 measurement every 5 minutes. We will have to synchronize the data to be able to compare them.\n",
    "\n",
    "> __Question 5.__ Resample the hydrological data to match the chemical data. You can use the `pd.DataFrame.resample()` method in order to do this. Take the time to read the documentation of this method, and to see implemented examples on the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum common start and end dates\n",
    "start = max(suspended_load.index.min(), data_hydro.index.min())\n",
    "end = min(suspended_load.index.max(), data_hydro.index.max())\n",
    "\n",
    "# Trucate the dataframes\n",
    "suspended_load = suspended_load.truncate(before=start, after=end)\n",
    "data_hydro_resampled = data_hydro.truncate(before=start, after=end).copy()\n",
    "\n",
    "# Interpolate on a fine time grid and reindex on the most constraining index\n",
    "data_hydro_resampled = data_hydro_resampled.resample(\"1min\")\n",
    "data_hydro_resampled = data_hydro_resampled.interpolate(method=\"linear\", limit=10)\n",
    "\n",
    "# Reindex\n",
    "data_hydro_resampled = data_hydro_resampled.reindex(suspended_load.index)\n",
    "\n",
    "# Gather the data in a single dataframe\n",
    "data = data_hydro_resampled.copy()\n",
    "data[\"suspended_load\"] = suspended_load\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Plot the data\n",
    "ax = data.plot(\n",
    "    subplots=True,\n",
    "    style=\".\",\n",
    "    grid=True,\n",
    "    xlabel=\"Date\",\n",
    "    legend=False,\n",
    "    ms=2,\n",
    ");\n",
    "\n",
    "# Labels\n",
    "ax[0].set_ylabel(\"$h$ (cm)\")\n",
    "ax[1].set_ylabel(\"$T$ (NTU)\")\n",
    "ax[2].set_ylabel(\"$C_S$ (mg/L)\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Inspect the dataset\n",
    "\n",
    "Now we can start to investigate correlations between the turbidity and the suspended load. We will start by plotting the data. We will also compute the correlation coefficient between the turbidity and the suspended load. The goal here is to get a first idea of the relationship between the turbidity and the suspended load. \n",
    "\n",
    "> __Question 6.__ Using the `pd.plotting.scatter_matrix()` function, inspect the relationship between the turbidity, water level and suspended load. What do you observe? Does the correlation coefficient give you a good idea of the relationship between the turbidity and the suspended load? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calibrate the turbidity probe with machine learning\n",
    "\n",
    "In this section, we will try several machine learning models to find the best one to predict the suspended load from the turbidity. We will use the `scikit-learn` library. \n",
    "\n",
    "We first need to formalize the problem we are trying to solve. The goal here is to find the relationship between the turbidity $x$ and the suspended load $y$. In other terms, we want to find a function $f_\\theta$ such that \n",
    "\n",
    "$$f_\\theta(x) = y$$\n",
    "\n",
    "This function is called a model, and its parameters are noted $\\theta$ = $(\\theta_1, \\theta_2, \\dots, \\theta_n)$. We will try several models and compare them to find the best one, namely $\\theta^*$ = $(\\theta_1^*, \\theta_2^*, \\dots, \\theta_n^*)$, that minimizes the error between the predicted suspended load and the measured suspended load."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. First naive trial with linear regression\n",
    "\n",
    "There is no real need to use the `scikit-learn` library to perform a linear regression. However, it is a good way to start to use the library and understand its _greybox_ approach. In the next cell, we will import a linear regression model, instantiate it, fit it to the data and plot the result. Following the notations above, the linear regression uses a model of the form\n",
    "\n",
    "$$y = f_\\theta(x) = \\theta_1 x + \\theta_0$$\n",
    "\n",
    "The parameters $\\theta_0$ and $\\theta_1$ are called the intercept and the slope, respectively. The goal of the linear regression is to find the best values for these parameters. In other terms, we want to find the best line that fits the data.\n",
    "\n",
    "> __Question 7.__ What is the error function minimized by the linear regression? What score do you obtain out of the linear regression? What does it mean? Do you think that splitting the data into a training and a testing set is useful here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename vectors\n",
    "y = np.ones(10)\n",
    "x = np.zeros(10) # Turn turbidity into a numpy array here\n",
    "\n",
    "# Reshape the vectors\n",
    "y = y.reshape(-1, 1)\n",
    "x = x.reshape(-1, 1)\n",
    "\n",
    "# Create a linear regression object\n",
    "model_1 = linear_model.LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model_1.fit(x, y)\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model_1.predict(x)\n",
    "\n",
    "# Plot results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Robust linear regression\n",
    "\n",
    "It is obvious that the linear regression struggles with outliers. Several solutions exist to deal with outliers. One of them is to use a robust linear regression, which performs the linear regression on a subset of the data and iteratively removes the outliers in a randomized way. The `scikit-learn` library provides a robust linear regression model. You can find more information about it in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RANSACRegressor.html).\n",
    "\n",
    "> __Question 8.__ Use the robust linear regression model to fit the data. What score do you obtain? How does it depend on the hyperparameters of the model? Do you think that splitting the data into a training and a testing set is useful here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Working in the log-log space\n",
    "\n",
    "As you were told quite a lot in the lecture, the representation of the data is very important. As you can understand from the scatter matrix plot that we did in the data preparation section, the density of measurements in higher for lower values of the suspended load. This is a problem for the linear regression, since it will tend to fit the data in the low range of suspended load. One way to deal with this problem is to work in the log-log space.\n",
    "\n",
    "> __Question 9.__ Make the inspection of the data in the log-log space. What do you observe? What is the score of the linear regression in the log-log space? What is the score of the robust linear regression in the log-log space? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Using a multivariate linear regression\n",
    "\n",
    "We have seen that the water level is also correlated with the suspended load. It is therefore interesting to use it as an additional feature to predict the suspended load. This is called a multivariate linear regression. The `scikit-learn` library provides a multivariate linear regression model. You can find more information about it in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "> __Question 10.__ Use the multivariate linear regression model to fit the data. What score do you obtain? How does it depend on the hyperparameters of the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Testing other models\n",
    "\n",
    "Now we can use the `scikit-learn` library to test other models. You can find a list of the available models in the [documentation](https://scikit-learn.org/stable/supervised_learning.html). You can also find a list of the available metrics in the [documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics). This is a good opportunity to understand the concept of greybox. You can also use the `scikit-learn` [cheat sheet](https://scikit-learn.org/stable/machine_learning_map.html) to help you choose the right model.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_static/ml_map.png)\n",
    "\n",
    "> __Question 11.__ Test other models and compare them. What is the best model, and why? Consider using a train-test split to answer this question. Argue your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use your model to predict the suspended load on a time period where no suspended load measurements are available\n",
    "\n",
    "Now it's time to use your model to predict the suspended load on a time period where no suspended load measurements are available. Based on the model comparison you did in the previous section, choose the best model and train it on the whole dataset. Then, use it to predict the suspended load on the period from 2015-03-01 to 2015-05-01. \n",
    "\n",
    "> __Question 12.__ Plot the predicted suspended load and the measured suspended load on the same plot. What do you observe? What special patterns do observe in the predicted suspended load that you do not observe in the measured suspended load? Try to explain these patterns in your own words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
